Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 1 (use --cores to define parallelism)
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	all
	1	compute_msf
	1	plot_aprs_msf_wcn
	3
Select jobs to execute...

[Sat Feb 13 00:23:13 2021]
rule compute_msf:
    input: ancestral_reconstruction/Homo_sapiens_ENSP00000364472_best_model_relaxed.pdb
    output: ancestral_reconstruction/Homo_sapiens_ENSP00000364472_best_model_relaxed.msf, ancestral_reconstruction/msf.csv
    jobid: 11

[Sat Feb 13 00:23:14 2021]
Error in rule compute_msf:
    jobid: 11
    output: ancestral_reconstruction/Homo_sapiens_ENSP00000364472_best_model_relaxed.msf, ancestral_reconstruction/msf.csv
    shell:
        
        for model in ancestral_reconstruction/*_best_model_relaxed.pdb 
        do
        ./src/calc_gnm.py $model 
        done &&
        paste ancestral_reconstruction/*.msf > ancestral_reconstruction/msf.csv
        done
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Removing output files of failed job compute_msf since they might be corrupted:
ancestral_reconstruction/Homo_sapiens_ENSP00000364472_best_model_relaxed.msf, ancestral_reconstruction/msf.csv
Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: /home/tmasson/APOA1_evolution/.snakemake/log/2021-02-13T002313.031837.snakemake.log
